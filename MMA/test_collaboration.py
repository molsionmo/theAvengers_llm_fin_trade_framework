#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šæ¯”è¾ƒè®­ç»ƒå‰åçš„æ¨¡å‹åä½œæ•ˆæœ
è¯„ä¼°åœ¨çœŸå®ä»»åŠ¡ä¸­ï¼Œé€‚é…å™¨è®­ç»ƒæ˜¯å¦èƒ½æ”¹å–„è·¨æ¨¡å‹åä½œçš„æ€§èƒ½
"""

import torch
import torch.nn.functional as F
import numpy as np
from transformers import AutoTokenizer, AutoModel, pipeline
import json
import time
from Multi import MultiModelCollaborator, AlignmentTrainer, AlignmentEvaluator

class CollaborationTester:
    """åä½œæ•ˆæœæµ‹è¯•å™¨"""
    
    def __init__(self, model1_name="bert-base-uncased", model2_name="gpt2"):
        print(f"åˆå§‹åŒ–æµ‹è¯•å™¨: {model1_name} + {model2_name}")
        self.model1 = AutoModel.from_pretrained(model1_name)
        self.model2 = AutoModel.from_pretrained(model2_name)
        self.collaborator = MultiModelCollaborator([self.model1, self.model2])
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®é›†
        self.test_scenarios = self._prepare_test_scenarios()
        
    def _prepare_test_scenarios(self):
        """å‡†å¤‡å¤šç§æµ‹è¯•åœºæ™¯"""
        return {
            "question_answering": [
                "What is the capital of France?",
                "Who wrote Romeo and Juliet?", 
                "What is the largest planet in our solar system?",
                "When did World War II end?",
                "What is the chemical symbol for gold?"
            ],
            "sentiment_analysis": [
                "I love this movie, it's amazing!",
                "This product is terrible and doesn't work.",
                "The weather today is quite pleasant.",
                "I'm feeling a bit sad about the news.",
                "This restaurant serves excellent food."
            ],
            "text_completion": [
                "The future of artificial intelligence",
                "Climate change is a serious issue",
                "Space exploration has always been",
                "Education in the digital age",
                "The importance of renewable energy"
            ],
            "semantic_similarity": [
                ("The cat is sleeping", "A feline is resting"),
                ("I love programming", "I enjoy coding"),
                ("The weather is cold", "It's freezing outside"),
                ("She is reading a book", "The woman is studying literature"),
                ("The car is fast", "The vehicle has high speed")
            ]
        }
    
    def test_hidden_state_quality(self, scenario_name, texts):
        """æµ‹è¯•hidden stateçš„è´¨é‡"""
        print(f"\næµ‹è¯•åœºæ™¯: {scenario_name}")
        results = {
            'untrained': {'cosine_similarities': [], 'mmd_losses': []},
            'trained': {'cosine_similarities': [], 'mmd_losses': []}
        }
        
        evaluator = AlignmentEvaluator(metrics=['cosine', 'mmd'])
        
        for text in texts:
            if isinstance(text, tuple):
                text = text[0]  # å¯¹äºè¯­ä¹‰ç›¸ä¼¼æ€§æµ‹è¯•ï¼Œåªå–ç¬¬ä¸€ä¸ªå¥å­
                
            # è·å–åŸå§‹hidden states
            hidden1 = self.collaborator.get_hidden_states(text, 0)
            hidden2 = self.collaborator.get_hidden_states(text, 1)
            
            # æœªè®­ç»ƒçš„å¯¹é½æ•ˆæœ
            untrained_cosine = evaluator.cosine_similarity(hidden1, hidden2)
            untrained_mmd = evaluator.mmd_loss(
                hidden1.view(-1, hidden1.size(-1)), 
                hidden2.view(-1, hidden2.size(-1))
            ).item()
            
            results['untrained']['cosine_similarities'].append(untrained_cosine)
            results['untrained']['mmd_losses'].append(untrained_mmd)
            
            # é€šè¿‡ä¸­å¿ƒå¤„ç†å±‚å¤„ç†åçš„å¯¹é½æ•ˆæœ
            projected_states = self.collaborator.central_processor.process([hidden1, hidden2])
            proj1, proj2 = projected_states
            
            trained_cosine = evaluator.cosine_similarity(proj1, proj2)
            trained_mmd = evaluator.mmd_loss(
                proj1.view(-1, proj1.size(-1)), 
                proj2.view(-1, proj2.size(-1))
            ).item()
            
            results['trained']['cosine_similarities'].append(trained_cosine)
            results['trained']['mmd_losses'].append(trained_mmd)
        
        return results
    
    def test_semantic_similarity_preservation(self):
        """æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼æ€§ä¿æŒèƒ½åŠ›"""
        print("\n=== è¯­ä¹‰ç›¸ä¼¼æ€§ä¿æŒæµ‹è¯• ===")
        
        similarity_pairs = self.test_scenarios["semantic_similarity"]
        results = {'untrained': [], 'trained': []}
        
        for text1, text2 in similarity_pairs:
            print(f"æµ‹è¯•å¯¹: '{text1}' vs '{text2}'")
            
            # è·å–åŸå§‹hidden states
            hidden1_1 = self.collaborator.get_hidden_states(text1, 0)
            hidden1_2 = self.collaborator.get_hidden_states(text2, 0)
            hidden2_1 = self.collaborator.get_hidden_states(text1, 1)
            hidden2_2 = self.collaborator.get_hidden_states(text2, 1)
            
            # æœªè®­ç»ƒæƒ…å†µï¼šç›´æ¥è®¡ç®—ç›¸ä¼¼æ€§
            # ä½¿ç”¨å¹³å‡æ± åŒ–è·å¾—å¥å­çº§è¡¨ç¤º
            sent1_bert = hidden1_1.mean(dim=1)
            sent2_bert = hidden1_2.mean(dim=1)
            sent1_gpt = hidden2_1.mean(dim=1)
            sent2_gpt = hidden2_2.mean(dim=1)
            
            untrained_bert_sim = F.cosine_similarity(sent1_bert, sent2_bert).item()
            untrained_gpt_sim = F.cosine_similarity(sent1_gpt, sent2_gpt).item()
            untrained_cross_sim = F.cosine_similarity(sent1_bert, sent1_gpt).item()
            
            # è®­ç»ƒåæƒ…å†µï¼šé€šè¿‡ä¸­å¿ƒå¤„ç†å±‚
            proj1_1, proj2_1 = self.collaborator.central_processor.process([hidden1_1, hidden2_1])
            proj1_2, proj2_2 = self.collaborator.central_processor.process([hidden1_2, hidden2_2])
            
            sent1_proj1 = proj1_1.mean(dim=1)
            sent2_proj1 = proj1_2.mean(dim=1)
            sent1_proj2 = proj2_1.mean(dim=1)
            sent2_proj2 = proj2_2.mean(dim=1)
            
            trained_proj1_sim = F.cosine_similarity(sent1_proj1, sent2_proj1).item()
            trained_proj2_sim = F.cosine_similarity(sent1_proj2, sent2_proj2).item()
            trained_cross_sim = F.cosine_similarity(sent1_proj1, sent1_proj2).item()
            
            results['untrained'].append({
                'bert_similarity': untrained_bert_sim,
                'gpt_similarity': untrained_gpt_sim,
                'cross_model_similarity': untrained_cross_sim
            })
            
            results['trained'].append({
                'proj1_similarity': trained_proj1_sim,
                'proj2_similarity': trained_proj2_sim,
                'cross_model_similarity': trained_cross_sim
            })
            
            print(f"  æœªè®­ç»ƒ - BERTç›¸ä¼¼æ€§: {untrained_bert_sim:.3f}, GPTç›¸ä¼¼æ€§: {untrained_gpt_sim:.3f}, è·¨æ¨¡å‹: {untrained_cross_sim:.3f}")
            print(f"  è®­ç»ƒå - æŠ•å½±1ç›¸ä¼¼æ€§: {trained_proj1_sim:.3f}, æŠ•å½±2ç›¸ä¼¼æ€§: {trained_proj2_sim:.3f}, è·¨æ¨¡å‹: {trained_cross_sim:.3f}")
        
        return results
    
    def test_information_transfer_quality(self):
        """æµ‹è¯•ä¿¡æ¯ä¼ é€’è´¨é‡"""
        print("\n=== ä¿¡æ¯ä¼ é€’è´¨é‡æµ‹è¯• ===")
        
        test_texts = self.test_scenarios["question_answering"]
        results = {'untrained': [], 'trained': []}
        
        for text in test_texts:
            print(f"æµ‹è¯•æ–‡æœ¬: '{text}'")
            
            # è·å–åä½œç»“æœ
            collaboration_output = self.collaborator.collaborate(text, 0, 1)
            adapted_hidden = collaboration_output['adapted_hidden']
            normal_hidden = collaboration_output['normal_hidden']
            
            # è®¡ç®—ä¿¡æ¯ä¿æŒåº¦ï¼ˆé€šè¿‡æ¯”è¾ƒç»´åº¦å’Œæ¿€æ´»æ¨¡å¼ï¼‰
            # 1. æ¿€æ´»å¼ºåº¦æ¯”è¾ƒ
            adapted_activation_strength = torch.norm(adapted_hidden, dim=-1).mean().item()
            normal_activation_strength = torch.norm(normal_hidden, dim=-1).mean().item()
            
            # 2. ä¿¡æ¯å¯†åº¦æ¯”è¾ƒï¼ˆé€šè¿‡æ–¹å·®è¡¡é‡ï¼‰
            adapted_variance = torch.var(adapted_hidden, dim=-1).mean().item()
            normal_variance = torch.var(normal_hidden, dim=-1).mean().item()
            
            # 3. è·¨æ¨¡å‹ä¸€è‡´æ€§
            # ç”±äºadapted_hiddenå’Œnormal_hiddenç»´åº¦ä¸åŒï¼Œéœ€è¦å…ˆç»Ÿä¸€ç»´åº¦
            adapted_mean = adapted_hidden.mean(dim=1)  # [1, 512]
            normal_mean = normal_hidden.mean(dim=1)    # [1, 768]
            
            # å°†ä¸¤è€…æŠ•å½±åˆ°ç›¸åŒç»´åº¦è¿›è¡Œæ¯”è¾ƒ
            min_dim = min(adapted_mean.size(-1), normal_mean.size(-1))
            adapted_reduced = adapted_mean[:, :min_dim]
            normal_reduced = normal_mean[:, :min_dim]
            
            cross_model_consistency = F.cosine_similarity(
                adapted_reduced, 
                normal_reduced
            ).item()
            
            result = {
                'activation_strength_ratio': adapted_activation_strength / normal_activation_strength,
                'variance_ratio': adapted_variance / normal_variance,
                'cross_model_consistency': cross_model_consistency
            }
            
            results['trained'].append(result)
            
            print(f"  æ¿€æ´»å¼ºåº¦æ¯”: {result['activation_strength_ratio']:.3f}")
            print(f"  æ–¹å·®æ¯”: {result['variance_ratio']:.3f}")
            print(f"  è·¨æ¨¡å‹ä¸€è‡´æ€§: {result['cross_model_consistency']:.3f}")
        
        return results
    
    def train_adapter(self, epochs=5):
        """è®­ç»ƒé€‚é…å™¨"""
        print(f"\n=== å¼€å§‹è®­ç»ƒé€‚é…å™¨ ({epochs} epochs) ===")
        
        trainer = AlignmentTrainer(self.collaborator, learning_rate=1e-4)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        train_texts = []
        for scenario_texts in self.test_scenarios.values():
            if isinstance(scenario_texts[0], tuple):
                # å¯¹äºè¯­ä¹‰ç›¸ä¼¼æ€§æ•°æ®ï¼Œæå–æ‰€æœ‰æ–‡æœ¬
                for pair in scenario_texts:
                    train_texts.extend(pair)
            else:
                train_texts.extend(scenario_texts)
        
        # æ·»åŠ æ›´å¤šè®­ç»ƒæ•°æ®
        additional_texts = [
            "Machine learning is transforming technology",
            "The ocean is vast and mysterious", 
            "Books contain endless knowledge",
            "Music brings people together",
            "Travel broadens one's perspective",
            "Friendship is valuable beyond measure",
            "Science helps us understand the world",
            "Art expresses human creativity"
        ]
        train_texts.extend(additional_texts)
        
        print(f"è®­ç»ƒæ•°æ®é‡: {len(train_texts)} æ¡æ–‡æœ¬")
        
        # è¯„ä¼°è®­ç»ƒå‰æ•ˆæœ
        val_texts = train_texts[:5]
        pre_train_results = trainer.evaluate_alignment(val_texts)
        print(f"è®­ç»ƒå‰å¯¹é½æ•ˆæœ - ä½™å¼¦ç›¸ä¼¼åº¦: {pre_train_results['cosine']:.4f}, MMD: {pre_train_results['mmd']:.4f}")
        
        # å¼€å§‹è®­ç»ƒ
        start_time = time.time()
        trainer.train(train_texts, epochs=epochs, validation_dataset=val_texts)
        training_time = time.time() - start_time
        
        # è¯„ä¼°è®­ç»ƒåæ•ˆæœ
        post_train_results = trainer.evaluate_alignment(val_texts)
        print(f"è®­ç»ƒåå¯¹é½æ•ˆæœ - ä½™å¼¦ç›¸ä¼¼åº¦: {post_train_results['cosine']:.4f}, MMD: {post_train_results['mmd']:.4f}")
        print(f"è®­ç»ƒè€—æ—¶: {training_time:.2f} ç§’")
        
        return pre_train_results, post_train_results
    
    def run_comprehensive_test(self, train_adapter=True):
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        print("=" * 60)
        print("ğŸš€ å¼€å§‹å¤šæ¨¡å‹åä½œæ•ˆæœç»¼åˆæµ‹è¯•")
        print("=" * 60)
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæµ‹è¯•æœªè®­ç»ƒçš„åä½œæ•ˆæœ
        print("\nğŸ“Š é˜¶æ®µ1: æµ‹è¯•æœªè®­ç»ƒçš„åŸºçº¿æ•ˆæœ")
        baseline_results = {}
        
        for scenario_name, texts in self.test_scenarios.items():
            if scenario_name != "semantic_similarity":
                results = self.test_hidden_state_quality(scenario_name, texts)
                baseline_results[scenario_name] = results['untrained']
        
        baseline_semantic = self.test_semantic_similarity_preservation()
        baseline_transfer = self.test_information_transfer_quality()
        
        # ç¬¬äºŒé˜¶æ®µï¼šè®­ç»ƒé€‚é…å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if train_adapter:
            training_results = self.train_adapter(epochs=5)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šæµ‹è¯•è®­ç»ƒåçš„åä½œæ•ˆæœ
        print("\nğŸ“Š é˜¶æ®µ2: æµ‹è¯•è®­ç»ƒåçš„åä½œæ•ˆæœ")
        trained_results = {}
        
        for scenario_name, texts in self.test_scenarios.items():
            if scenario_name != "semantic_similarity":
                results = self.test_hidden_state_quality(scenario_name, texts)
                trained_results[scenario_name] = results['trained']
        
        trained_semantic = self.test_semantic_similarity_preservation()
        trained_transfer = self.test_information_transfer_quality()
        
        # ç¬¬å››é˜¶æ®µï¼šç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self._generate_comparison_report(
            baseline_results, trained_results, 
            baseline_semantic, trained_semantic,
            baseline_transfer, trained_transfer,
            training_results if train_adapter else None
        )
    
    def _generate_comparison_report(self, baseline_results, trained_results, 
                                   baseline_semantic, trained_semantic,
                                   baseline_transfer, trained_transfer,
                                   training_results):
        """ç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ åä½œæ•ˆæœå¯¹æ¯”æŠ¥å‘Š")
        print("=" * 60)
        
        # 1. Hidden Stateå¯¹é½æ•ˆæœå¯¹æ¯”
        print("\n1ï¸âƒ£  Hidden Stateå¯¹é½æ•ˆæœå¯¹æ¯”:")
        print("-" * 40)
        
        for scenario in baseline_results.keys():
            baseline_cosine = np.mean(baseline_results[scenario]['cosine_similarities'])
            trained_cosine = np.mean(trained_results[scenario]['cosine_similarities'])
            baseline_mmd = np.mean(baseline_results[scenario]['mmd_losses'])
            trained_mmd = np.mean(trained_results[scenario]['mmd_losses'])
            
            cosine_improvement = ((trained_cosine - baseline_cosine) / abs(baseline_cosine)) * 100
            mmd_improvement = ((baseline_mmd - trained_mmd) / baseline_mmd) * 100
            
            print(f"\nğŸ“ {scenario.replace('_', ' ').title()}:")
            print(f"   ä½™å¼¦ç›¸ä¼¼åº¦: {baseline_cosine:.4f} â†’ {trained_cosine:.4f} (æ”¹å–„: {cosine_improvement:+.1f}%)")
            print(f"   MMDæŸå¤±:    {baseline_mmd:.4f} â†’ {trained_mmd:.4f} (æ”¹å–„: {mmd_improvement:+.1f}%)")
        
        # 2. è¯­ä¹‰ç›¸ä¼¼æ€§ä¿æŒå¯¹æ¯”
        print("\n2ï¸âƒ£  è¯­ä¹‰ç›¸ä¼¼æ€§ä¿æŒå¯¹æ¯”:")
        print("-" * 40)
        
        baseline_cross = np.mean([r['cross_model_similarity'] for r in baseline_semantic['untrained']])
        trained_cross = np.mean([r['cross_model_similarity'] for r in trained_semantic['trained']])
        cross_improvement = ((trained_cross - baseline_cross) / abs(baseline_cross)) * 100
        
        print(f"   è·¨æ¨¡å‹è¯­ä¹‰ä¸€è‡´æ€§: {baseline_cross:.4f} â†’ {trained_cross:.4f} (æ”¹å–„: {cross_improvement:+.1f}%)")
        
        # 3. ä¿¡æ¯ä¼ é€’è´¨é‡
        print("\n3ï¸âƒ£  ä¿¡æ¯ä¼ é€’è´¨é‡åˆ†æ:")
        print("-" * 40)
        
        avg_activation_ratio = np.mean([r['activation_strength_ratio'] for r in trained_transfer['trained']])
        avg_variance_ratio = np.mean([r['variance_ratio'] for r in trained_transfer['trained']])
        avg_consistency = np.mean([r['cross_model_consistency'] for r in trained_transfer['trained']])
        
        print(f"   å¹³å‡æ¿€æ´»å¼ºåº¦æ¯”: {avg_activation_ratio:.3f}")
        print(f"   å¹³å‡æ–¹å·®æ¯”:     {avg_variance_ratio:.3f}")
        print(f"   å¹³å‡è·¨æ¨¡å‹ä¸€è‡´æ€§: {avg_consistency:.3f}")
        
        # 4. è®­ç»ƒæ•ˆæœæ€»ç»“
        if training_results:
            print("\n4ï¸âƒ£  è®­ç»ƒæ•ˆæœæ€»ç»“:")
            print("-" * 40)
            pre_cosine = training_results[0]['cosine']
            post_cosine = training_results[1]['cosine']
            pre_mmd = training_results[0]['mmd']
            post_mmd = training_results[1]['mmd']
            
            cosine_train_improvement = ((post_cosine - pre_cosine) / abs(pre_cosine)) * 100
            mmd_train_improvement = ((pre_mmd - post_mmd) / pre_mmd) * 100
            
            print(f"   è®­ç»ƒæœŸé—´ä½™å¼¦ç›¸ä¼¼åº¦æå‡: {cosine_train_improvement:+.1f}%")
            print(f"   è®­ç»ƒæœŸé—´MMDæŸå¤±é™ä½:   {mmd_train_improvement:+.1f}%")
        
        # 5. ç»“è®ºå’Œå»ºè®®
        print("\n5ï¸âƒ£  ç»“è®ºå’Œå»ºè®®:")
        print("-" * 40)
        
        overall_improvement = (cross_improvement + cosine_improvement) / 2
        
        if overall_improvement > 10:
            conclusion = "ğŸ‰ è®­ç»ƒæ˜¾è‘—æ”¹å–„äº†æ¨¡å‹åä½œæ•ˆæœï¼"
        elif overall_improvement > 5:
            conclusion = "âœ… è®­ç»ƒé€‚åº¦æ”¹å–„äº†æ¨¡å‹åä½œæ•ˆæœã€‚"
        elif overall_improvement > 0:
            conclusion = "ğŸ“ˆ è®­ç»ƒç•¥å¾®æ”¹å–„äº†æ¨¡å‹åä½œæ•ˆæœã€‚"
        else:
            conclusion = "âš ï¸  è®­ç»ƒæ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®è°ƒæ•´è®­ç»ƒç­–ç•¥ã€‚"
        
        print(f"   {conclusion}")
        print(f"   æ€»ä½“æ”¹å–„åº¦: {overall_improvement:+.1f}%")
        
        if avg_consistency > 0.5:
            print("   âœ… è·¨æ¨¡å‹ä¿¡æ¯ä¼ é€’è´¨é‡è‰¯å¥½")
        else:
            print("   âš ï¸  è·¨æ¨¡å‹ä¿¡æ¯ä¼ é€’éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
        
        print("\n" + "=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¤šæ¨¡å‹åä½œæ•ˆæœæµ‹è¯•è„šæœ¬")
    print("æ­¤è„šæœ¬å°†æ¯”è¾ƒè®­ç»ƒå‰åçš„åä½œæ•ˆæœ")
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = CollaborationTester()
    
    # è¿è¡Œç»¼åˆæµ‹è¯•
    tester.run_comprehensive_test(train_adapter=True)


if __name__ == "__main__":
    main()
