#!/usr/bin/env python3
"""
ä»»åŠ¡æ„ŸçŸ¥å¤šæ¨¡å‹åä½œç³»ç»Ÿæ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä»»åŠ¡æ„ŸçŸ¥çš„å¤šæ¨¡å‹åä½œæ¡†æ¶
"""

import sys
import os

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from transformers import AutoModel
from src.core.collaborator import MultiModelCollaborator
from src.tasks.detector import TaskType
from src.training.task_aware_trainer import TaskAwareTrainer


def basic_demo():
    """åŸºç¡€æ¼”ç¤ºï¼šä»»åŠ¡æ£€æµ‹å’Œåä½œ"""
    print("ğŸš€ ä»»åŠ¡æ„ŸçŸ¥å¤šæ¨¡å‹åä½œåŸºç¡€æ¼”ç¤º")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model1 = AutoModel.from_pretrained("bert-base-uncased")
    model2 = AutoModel.from_pretrained("gpt2")
    
    # åˆ›å»ºåä½œç³»ç»Ÿ
    collaborator = MultiModelCollaborator([model1, model2])
    
    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "What is machine learning?",
        "I love this product!",
        "Write a story about space",
        "Hello, how are you?",
        "The weather is nice today."
    ]
    
    print("\nğŸ“‹ ä»»åŠ¡æ£€æµ‹æ¼”ç¤º:")
    for text in test_texts:
        detected_task = collaborator.detect_task_for_text(text)
        confidence = collaborator.get_task_confidence(text)
        
        print(f"æ–‡æœ¬: '{text}'")
        print(f"  æ£€æµ‹ä»»åŠ¡: {detected_task.value}")
        print(f"  ç½®ä¿¡åº¦: {max(confidence.values()):.3f}")
        print()
    
    print("ğŸ“Š åä½œæ¼”ç¤º:")
    test_text = "What is the capital of France?"
    result = collaborator.collaborate(test_text, 0, 1)
    print(f"æ–‡æœ¬: '{test_text}'")
    print(f"é€‚é…åhidden shape: {result['adapted_hidden'].shape}")
    print(f"åŸå§‹hidden shape: {result['normal_hidden'].shape}")
    
    print("\nâœ… åŸºç¡€æ¼”ç¤ºå®Œæˆ!")


def training_demo():
    """è®­ç»ƒæ¼”ç¤ºï¼šä»»åŠ¡æ„ŸçŸ¥è®­ç»ƒ"""
    print("ğŸ”§ ä»»åŠ¡æ„ŸçŸ¥è®­ç»ƒæ¼”ç¤º")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model1 = AutoModel.from_pretrained("bert-base-uncased")
    model2 = AutoModel.from_pretrained("gpt2")
    
    # åˆ›å»ºåä½œç³»ç»Ÿ
    collaborator = MultiModelCollaborator([model1, model2])
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = TaskAwareTrainer(collaborator, learning_rate=1e-4)
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    train_texts = [
        "What is artificial intelligence?",
        "How does neural network work?",
        "I love machine learning!",
        "This framework is amazing!",
        "Write a poem about technology",
        "Create a story about robots",
        "Hello there!",
        "Good morning everyone!",
        "The sky is blue today",
        "Technology advances rapidly"
    ]
    
    print("ğŸ“ˆ æ•°æ®é›†ä»»åŠ¡åˆ†å¸ƒ:")
    distribution = trainer.get_task_distribution(train_texts)
    for task, ratio in distribution.items():
        print(f"  {task}: {ratio:.2%}")
    
    print("\nğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")
    results = trainer.train_with_task_awareness(train_texts, epochs=3)
    
    print("\nğŸ“Š è®­ç»ƒç»“æœæ‘˜è¦:")
    summary = trainer.get_task_performance_summary()
    for task, metrics in summary.items():
        print(f"{task}:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.4f}")
    
    print("\nâœ… è®­ç»ƒæ¼”ç¤ºå®Œæˆ!")


def comparison_demo():
    """å¯¹æ¯”æ¼”ç¤ºï¼šä»»åŠ¡æ„ŸçŸ¥ vs é€šç”¨åä½œ"""
    print("âš–ï¸ ä»»åŠ¡æ„ŸçŸ¥ vs é€šç”¨åä½œå¯¹æ¯”")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model1 = AutoModel.from_pretrained("bert-base-uncased")
    model2 = AutoModel.from_pretrained("gpt2")
    
    # åˆ›å»ºåä½œç³»ç»Ÿ
    collaborator = MultiModelCollaborator([model1, model2])
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        ("What is the capital of Japan?", TaskType.QUESTION_ANSWERING),
        ("I hate this movie!", TaskType.SENTIMENT_ANALYSIS),
        ("Generate a creative story", TaskType.TEXT_GENERATION),
    ]
    
    print("\nğŸ” åä½œæ•ˆæœå¯¹æ¯”:")
    for text, task_type in test_cases:
        print(f"\næ–‡æœ¬: '{text}' (ä»»åŠ¡: {task_type.value})")
        
        # é€šç”¨åä½œ
        general_result = collaborator.collaborate(text, 0, 1, task_type=None)
        
        # ä»»åŠ¡æ„ŸçŸ¥åä½œ
        task_aware_result = collaborator.collaborate(text, 0, 1, task_type=task_type)
        
        # è®¡ç®—å·®å¼‚
        import torch.nn.functional as F
        similarity_general = F.cosine_similarity(
            general_result['source_hidden'].mean(dim=1),
            general_result['adapted_hidden'].mean(dim=1)
        ).item()
        
        similarity_task_aware = F.cosine_similarity(
            task_aware_result['source_hidden'].mean(dim=1),
            task_aware_result['adapted_hidden'].mean(dim=1)
        ).item()
        
        print(f"  é€šç”¨åä½œç›¸ä¼¼åº¦: {similarity_general:.4f}")
        print(f"  ä»»åŠ¡æ„ŸçŸ¥ç›¸ä¼¼åº¦: {similarity_task_aware:.4f}")
        print(f"  æ”¹å–„ç¨‹åº¦: {similarity_task_aware - similarity_general:+.4f}")
    
    print("\nâœ… å¯¹æ¯”æ¼”ç¤ºå®Œæˆ!")


def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤º"""
    print("ğŸ® äº¤äº’å¼ä»»åŠ¡æ„ŸçŸ¥åä½œæ¼”ç¤º")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
    model1 = AutoModel.from_pretrained("bert-base-uncased")
    model2 = AutoModel.from_pretrained("gpt2")
    
    # åˆ›å»ºåä½œç³»ç»Ÿ
    collaborator = MultiModelCollaborator([model1, model2])
    
    print("âœ¨ è¾“å…¥æ–‡æœ¬æ¥æµ‹è¯•ä»»åŠ¡æ£€æµ‹å’Œåä½œæ•ˆæœ")
    print("è¾“å…¥ 'quit' é€€å‡ºæ¼”ç¤º")
    print()
    
    while True:
        try:
            user_input = input("è¯·è¾“å…¥æ–‡æœ¬: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q']:
                break
            
            if not user_input:
                continue
            
            # æ£€æµ‹ä»»åŠ¡
            detected_task = collaborator.detect_task_for_text(user_input)
            confidence = collaborator.get_task_confidence(user_input)
            
            print(f"ğŸ¯ æ£€æµ‹ç»“æœ:")
            print(f"  ä»»åŠ¡ç±»å‹: {detected_task.value}")
            print(f"  ç½®ä¿¡åº¦: {max(confidence.values()):.3f}")
            
            # åä½œæµ‹è¯•
            result = collaborator.collaborate(user_input, 0, 1, task_type=detected_task)
            print(f"ğŸ“Š åä½œç»“æœ:")
            print(f"  é€‚é…ç»´åº¦: {result['adapted_hidden'].shape}")
            print(f"  ä»»åŠ¡ç±»å‹: {result['task_type'].value if result['task_type'] else 'None'}")
            print()
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            print()
    
    print("ğŸ‘‹ å†è§!")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        
        if mode == "basic":
            basic_demo()
        elif mode == "training":
            training_demo()
        elif mode == "comparison":
            comparison_demo()
        elif mode == "interactive":
            interactive_demo()
        elif mode == "help":
            print("ğŸ”§ ä»»åŠ¡æ„ŸçŸ¥å¤šæ¨¡å‹åä½œæ¼”ç¤º")
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python demo.py basic        - åŸºç¡€åŠŸèƒ½æ¼”ç¤º")
            print("  python demo.py training     - è®­ç»ƒè¿‡ç¨‹æ¼”ç¤º")
            print("  python demo.py comparison   - æ•ˆæœå¯¹æ¯”æ¼”ç¤º")
            print("  python demo.py interactive  - äº¤äº’å¼æ¼”ç¤º")
            print("  python demo.py help         - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            print("ä½¿ç”¨ 'python demo.py help' æŸ¥çœ‹å¯ç”¨æ¨¡å¼")
    else:
        # é»˜è®¤è¿è¡ŒåŸºç¡€æ¼”ç¤º
        basic_demo()


if __name__ == "__main__":
    main()
