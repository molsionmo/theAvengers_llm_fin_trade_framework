# æ•°æ®é¢„å¤„ç†å’Œè®­ç»ƒæŒ‡å—

æœ¬é¡¹ç›®ç°åœ¨æ”¯æŒä»äº’è”ç½‘æ•°æ®é›†è‡ªåŠ¨ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®ï¼Œç”¨äºè®­ç»ƒä»»åŠ¡æ„ŸçŸ¥é€‚é…å™¨ã€‚æœ¬æŒ‡å—å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨è¿™äº›æ–°åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. æŸ¥çœ‹å¯ç”¨æ•°æ®é›†

```bash
python main.py data list
```

è¿™å°†æ˜¾ç¤ºæ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†ï¼ŒæŒ‰ä»»åŠ¡ç±»å‹åˆ†ç»„ï¼š

- **é—®ç­”ä»»åŠ¡**: SQuAD, SQuAD v2
- **æƒ…æ„Ÿåˆ†æ**: IMDB, SST-2
- **æ–‡æœ¬åˆ†ç±»**: AG News, 20 Newsgroups
- **æ–‡æœ¬ç›¸ä¼¼åº¦**: STS Benchmark
- **è‡ªç„¶è¯­è¨€æ¨ç†**: SNLI, MNLI
- **æ–‡æœ¬ç”Ÿæˆ**: WikiText, OpenWebText
- **å¯¹è¯ä»»åŠ¡**: Persona Chat
- **æ‘˜è¦ä»»åŠ¡**: CNN/DailyMail, XSum

### 3. åˆ›å»ºæ··åˆæ•°æ®é›†

```bash
python main.py data create-mixed imdb ag_news squad --max-samples-per-dataset 1000 --output-dir ./my_data
```

è¿™å°†ï¼š
- ä»IMDBã€AG Newså’ŒSQuADæ•°æ®é›†å„ä¸‹è½½1000ä¸ªæ ·æœ¬
- é¢„å¤„ç†ä¸ºé€‚åˆè®­ç»ƒçš„æ ¼å¼
- ä¿å­˜åˆ°`./my_data`ç›®å½•

### 4. ä½¿ç”¨æ•°æ®é›†è®­ç»ƒ

```bash
python main.py train-with-data imdb ag_news --epochs 10 --batch-size 16 --data-dir ./my_data
```

## ğŸ“Š æ•°æ®é¢„å¤„ç†åŠŸèƒ½

### æ”¯æŒçš„æ•°æ®é›†ç±»å‹

| ä»»åŠ¡ç±»å‹ | æ•°æ®é›†ç¤ºä¾‹ | ç”¨é€” |
|---------|-----------|------|
| question_answering | squad, squad_v2 | é—®ç­”ç³»ç»Ÿè®­ç»ƒ |
| sentiment_analysis | imdb, sst2 | æƒ…æ„Ÿåˆ†æè®­ç»ƒ |
| text_classification | ag_news, 20newsgroups | æ–‡æœ¬åˆ†ç±»è®­ç»ƒ |
| text_similarity | sts_benchmark | è¯­ä¹‰ç›¸ä¼¼åº¦è®­ç»ƒ |
| natural_language_inference | snli, mnli | è‡ªç„¶è¯­è¨€æ¨ç†è®­ç»ƒ |
| text_generation | wikitext, openwebtext | æ–‡æœ¬ç”Ÿæˆè®­ç»ƒ |
| conversation | persona_chat | å¯¹è¯ç³»ç»Ÿè®­ç»ƒ |
| summarization | cnn_dailymail, xsum | æ–‡æœ¬æ‘˜è¦è®­ç»ƒ |

### æ•°æ®é¢„å¤„ç†å‘½ä»¤

#### åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†
```bash
python scripts/preprocess_data.py list
```

#### ä¸‹è½½å•ä¸ªæ•°æ®é›†
```bash
python scripts/preprocess_data.py download imdb --max-samples 500 --output-dir ./data
```

#### åˆ›å»ºæ··åˆæ•°æ®é›†
```bash
python scripts/preprocess_data.py create-mixed imdb ag_news squad --max-samples-per-dataset 1000 --output-dir ./mixed_data
```

#### é¢„å¤„ç†ç”¨äºä»»åŠ¡æ£€æµ‹
```bash
python scripts/preprocess_data.py preprocess-task imdb ag_news --max-samples-per-dataset 500 --output-dir ./task_data
```

#### é¢„å¤„ç†ç”¨äºé€‚é…å™¨è®­ç»ƒ
```bash
python scripts/preprocess_data.py preprocess-adapter imdb ag_news --max-samples-per-dataset 1000 --tokenizer bert-base-uncased --output-dir ./adapter_data
```

#### éªŒè¯å¤„ç†åçš„æ•°æ®
```bash
python scripts/preprocess_data.py validate ./processed_data
```

#### æŸ¥çœ‹æ•°æ®ç»Ÿè®¡ä¿¡æ¯
```bash
python scripts/preprocess_data.py stats ./processed_data
```

## ğŸ¯ ä»»åŠ¡æ„ŸçŸ¥è®­ç»ƒ

### è®­ç»ƒå‚æ•°é…ç½®

ä½¿ç”¨`train-with-data`å‘½ä»¤æ—¶ï¼Œå¯ä»¥é…ç½®ä»¥ä¸‹å‚æ•°ï¼š

- `--epochs`: è®­ç»ƒè½®æ•° (é»˜è®¤: 10)
- `--batch-size`: æ‰¹æ¬¡å¤§å° (é»˜è®¤: 16)
- `--learning-rate`: å­¦ä¹ ç‡ (é»˜è®¤: 1e-4)
- `--max-samples-per-dataset`: æ¯ä¸ªæ•°æ®é›†çš„æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: 1000)
- `--sampling-strategy`: ä»»åŠ¡é‡‡æ ·ç­–ç•¥ (balanced/proportional/random, é»˜è®¤: balanced)
- `--validation-split`: éªŒè¯é›†æ¯”ä¾‹ (é»˜è®¤: 0.2)
- `--tokenizer`: åˆ†è¯å™¨åç§° (é»˜è®¤: bert-base-uncased)

### ç¤ºä¾‹è®­ç»ƒå‘½ä»¤

```bash
# åŸºç¡€è®­ç»ƒ
python main.py train-with-data imdb ag_news

# é«˜çº§é…ç½®è®­ç»ƒ
python main.py train-with-data imdb ag_news squad sst2 \
    --epochs 15 \
    --batch-size 32 \
    --learning-rate 5e-5 \
    --max-samples-per-dataset 2000 \
    --sampling-strategy balanced \
    --validation-split 0.15
```

## ğŸ”§ ä»»åŠ¡é‡‡æ ·ç­–ç•¥

### balanced (å¹³è¡¡é‡‡æ ·)
- æ¯ä¸ªä»»åŠ¡ç±»å‹è·å¾—ç›¸ç­‰çš„é‡‡æ ·æƒé‡
- é€‚ç”¨äºå¸Œæœ›æ¨¡å‹å¯¹æ‰€æœ‰ä»»åŠ¡ç±»å‹éƒ½æœ‰è‰¯å¥½æ€§èƒ½çš„åœºæ™¯

### proportional (æ¯”ä¾‹é‡‡æ ·)
- æŒ‰ç…§åŸå§‹æ•°æ®é›†ä¸­çš„ä»»åŠ¡åˆ†å¸ƒè¿›è¡Œé‡‡æ ·
- ä¿æŒæ•°æ®çš„è‡ªç„¶åˆ†å¸ƒ

### random (éšæœºé‡‡æ ·)
- å®Œå…¨éšæœºé‡‡æ ·
- ç”¨äºæ¢ç´¢æ€§å®éªŒ

## ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡å’Œåˆ†æ

### æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
```python
from src.data.dataset_loader import DatasetLoader

loader = DatasetLoader('./processed_data')
stats = loader.get_data_statistics()
print(stats)
```

### ä»»åŠ¡æ„ŸçŸ¥æ•°æ®é›†åŠŸèƒ½
```python
from src.data.task_dataset import TaskAwareDataset

# åˆ›å»ºä»»åŠ¡æ„ŸçŸ¥æ•°æ®é›†
dataset = TaskAwareDataset(
    data,
    tokenizer,
    task_sampling_strategy='balanced',
    include_task_tokens=True
)

# è·å–ç‰¹å®šä»»åŠ¡çš„æ‰¹æ¬¡
qa_batch = dataset.get_task_batch('question_answering', batch_size=8)

# è·å–æ··åˆä»»åŠ¡æ‰¹æ¬¡
mixed_batch = dataset.get_mixed_task_batch(batch_size=16)

# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
stats = dataset.get_task_statistics()
```

## ğŸ® æ¼”ç¤ºè„šæœ¬

è¿è¡Œæ•°æ®é¢„å¤„ç†æ¼”ç¤ºï¼š
```bash
python examples/data_preprocessing_demo.py
```

è¿™ä¸ªæ¼”ç¤ºå°†ï¼š
1. å±•ç¤ºå¦‚ä½•ä¸‹è½½å’Œé¢„å¤„ç†æ•°æ®é›†
2. åˆ›å»ºä»»åŠ¡æ„ŸçŸ¥æ•°æ®é›†
3. ä½¿ç”¨æ•°æ®é›†è¿›è¡Œé€‚é…å™¨è®­ç»ƒ
4. æ˜¾ç¤ºè®­ç»ƒç»“æœå’Œç»Ÿè®¡ä¿¡æ¯

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ç½‘ç»œè¿æ¥**: é¦–æ¬¡è¿è¡Œéœ€è¦ä»HuggingFaceä¸‹è½½æ•°æ®é›†ï¼Œç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
2. **å­˜å‚¨ç©ºé—´**: æŸäº›æ•°æ®é›†è¾ƒå¤§ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´
3. **å†…å­˜ä½¿ç”¨**: å¤§æ•°æ®é›†å¯èƒ½éœ€è¦è¾ƒå¤šå†…å­˜ï¼Œå¯ä»¥é€šè¿‡`--max-samples-per-dataset`å‚æ•°é™åˆ¶æ ·æœ¬æ•°é‡
4. **GPUæ”¯æŒ**: è®­ç»ƒè¿‡ç¨‹æ”¯æŒGPUåŠ é€Ÿï¼Œå¦‚æœæœ‰CUDAå¯ç”¨ä¼šè‡ªåŠ¨ä½¿ç”¨

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ä¸‹è½½è¶…æ—¶**: å¯ä»¥è®¾ç½®HuggingFaceä»£ç†æˆ–ä½¿ç”¨ç¼“å­˜
2. **å†…å­˜ä¸è¶³**: å‡å°‘æ‰¹æ¬¡å¤§å°å’Œæ ·æœ¬æ•°é‡
3. **CUDAé”™è¯¯**: ç¡®ä¿PyTorch CUDAç‰ˆæœ¬ä¸ç³»ç»ŸCUDAç‰ˆæœ¬åŒ¹é…

### è·å–å¸®åŠ©

```bash
python main.py --help
python scripts/preprocess_data.py --help
```

## ğŸ“ ç¤ºä¾‹å·¥ä½œæµ

å®Œæ•´çš„æ•°æ®é¢„å¤„ç†å’Œè®­ç»ƒå·¥ä½œæµï¼š

```bash
# 1. æŸ¥çœ‹å¯ç”¨æ•°æ®é›†
python main.py data list

# 2. åˆ›å»ºæ··åˆæ•°æ®é›†
python main.py data create-mixed imdb ag_news squad \
    --max-samples-per-dataset 1000 \
    --output-dir ./training_data

# 3. éªŒè¯æ•°æ®
python main.py data validate ./training_data

# 4. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
python main.py data stats ./training_data

# 5. å¼€å§‹è®­ç»ƒ
python main.py train-with-data imdb ag_news squad \
    --data-dir ./training_data \
    --epochs 10 \
    --batch-size 16

# 6. è¿è¡Œè¯„ä¼°æµ‹è¯•
python main.py test
```

è¿™æ ·å°±å®Œæˆäº†ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æµç¨‹ï¼
