#!/usr/bin/env python3
"""
éªŒè¯è¯„ä¼°ç»“æœçš„çœŸå®æ€§
å±•ç¤ºå…·ä½“è¯æ®ï¼Œè¯æ˜è®­ç»ƒç¡®å®æˆåŠŸäº†
"""

import json

def verify_results():
    print("ğŸ” éªŒè¯è¯„ä¼°ç»“æœçš„çœŸå®æ€§")
    print("=" * 60)
    
    # è¯»å–ä¸¤ä¸ªç»“æœæ–‡ä»¶
    with open("./eval_results_base_model_200samples.json", 'r') as f:
        base_results = json.load(f)
    
    with open("./experiments/Qwen2.5-1.5B-Instruct-gsm8k-group4-lora32-rmin0.98-temp0.5/checkpoint-2000/eval_results.json", 'r') as f:
        trained_results = json.load(f)
    
    print("ğŸ“Š åŸå§‹æ•°æ®éªŒè¯:")
    print(f"åŸºç¡€æ¨¡å‹æ–‡ä»¶å¤§å°: {len(str(base_results))} å­—ç¬¦")
    print(f"è®­ç»ƒæ¨¡å‹æ–‡ä»¶å¤§å°: {len(str(trained_results))} å­—ç¬¦")
    print(f"åŸºç¡€æ¨¡å‹æ ·æœ¬æ•°: {len(base_results['results'])}")
    print(f"è®­ç»ƒæ¨¡å‹æ ·æœ¬æ•°: {len(trained_results['results'])}")
    
    # æ‰‹åŠ¨è®¡ç®—å‡†ç¡®ç‡éªŒè¯
    base_correct = sum(1 for r in base_results['results'] if r['correct'])
    trained_correct = sum(1 for r in trained_results['results'] if r['correct'])
    
    print(f"\nğŸ§® æ‰‹åŠ¨è®¡ç®—éªŒè¯:")
    print(f"åŸºç¡€æ¨¡å‹æ­£ç¡®æ•°: {base_correct}/{len(base_results['results'])} = {base_correct/len(base_results['results'])*100:.1f}%")
    print(f"è®­ç»ƒæ¨¡å‹æ­£ç¡®æ•°: {trained_correct}/{len(trained_results['results'])} = {trained_correct/len(trained_results['results'])*100:.1f}%")
    
    # æ˜¾ç¤ºå…·ä½“çš„è¾“å‡ºè´¨é‡å·®å¼‚
    print(f"\nğŸ“ è¾“å‡ºè´¨é‡å¯¹æ¯” (å‰3ä¸ªæ ·æœ¬):")
    
    for i in range(3):
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"è¾“å…¥: {base_results['results'][i]['context'][:60]}...")
        print(f"æ­£ç¡®ç­”æ¡ˆ: {base_results['results'][i]['true_answer']}")
        
        print(f"\nğŸ¤– åŸºç¡€æ¨¡å‹è¾“å‡º:")
        print(f"   ç­”æ¡ˆ: {base_results['results'][i]['generated_answer']}")
        print(f"   å®Œæ•´å›å¤: {base_results['results'][i]['full_response'][:80]}...")
        print(f"   æ˜¯å¦æ­£ç¡®: {'âœ…' if base_results['results'][i]['correct'] else 'âŒ'}")
        
        print(f"\nğŸ§  è®­ç»ƒæ¨¡å‹è¾“å‡º:")
        print(f"   ç­”æ¡ˆ: {trained_results['results'][i]['generated_answer']}")
        print(f"   å®Œæ•´å›å¤: {trained_results['results'][i]['full_response'][:80]}...")
        print(f"   æ˜¯å¦æ­£ç¡®: {'âœ…' if trained_results['results'][i]['correct'] else 'âŒ'}")
        print("-" * 40)
    
    # åˆ†æè¾“å‡ºé•¿åº¦åˆ†å¸ƒ
    base_lengths = [len(r['full_response']) for r in base_results['results']]
    trained_lengths = [len(r['full_response']) for r in trained_results['results']]
    
    print(f"\nğŸ“ è¾“å‡ºé•¿åº¦åˆ†æ:")
    print(f"åŸºç¡€æ¨¡å‹: æœ€çŸ­={min(base_lengths)}, æœ€é•¿={max(base_lengths)}, å¹³å‡={sum(base_lengths)/len(base_lengths):.0f}")
    print(f"è®­ç»ƒæ¨¡å‹: æœ€çŸ­={min(trained_lengths)}, æœ€é•¿={max(trained_lengths)}, å¹³å‡={sum(trained_lengths)/len(trained_lengths):.0f}")
    
    # åˆ†ææ¨ç†è´¨é‡
    def has_reasoning(response):
        reasoning_indicators = ['analyze', 'determine', 'based on', 'therefore', 'considering', 'context']
        return any(indicator in response.lower() for indicator in reasoning_indicators)
    
    base_with_reasoning = sum(1 for r in base_results['results'] if has_reasoning(r['full_response']))
    trained_with_reasoning = sum(1 for r in trained_results['results'] if has_reasoning(r['full_response']))
    
    print(f"\nğŸ§  æ¨ç†èƒ½åŠ›åˆ†æ:")
    print(f"åŸºç¡€æ¨¡å‹åŒ…å«æ¨ç†çš„å›ç­”: {base_with_reasoning}/{len(base_results['results'])} ({base_with_reasoning/len(base_results['results'])*100:.1f}%)")
    print(f"è®­ç»ƒæ¨¡å‹åŒ…å«æ¨ç†çš„å›ç­”: {trained_with_reasoning}/{len(trained_results['results'])} ({trained_with_reasoning/len(trained_results['results'])*100:.1f}%)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸æ¨¡å¼
    print(f"\nğŸ” å¼‚å¸¸æ£€æµ‹:")
    
    # æ£€æŸ¥åŸºç¡€æ¨¡å‹æ˜¯å¦æœ‰é‡å¤è¾“å‡ºé—®é¢˜
    base_responses = [r['full_response'] for r in base_results['results']]
    unique_base_responses = len(set(base_responses))
    print(f"åŸºç¡€æ¨¡å‹ç‹¬ç‰¹å›ç­”æ•°: {unique_base_responses}/{len(base_responses)} (å¤šæ ·æ€§: {unique_base_responses/len(base_responses)*100:.1f}%)")
    
    trained_responses = [r['full_response'] for r in trained_results['results']]
    unique_trained_responses = len(set(trained_responses))
    print(f"è®­ç»ƒæ¨¡å‹ç‹¬ç‰¹å›ç­”æ•°: {unique_trained_responses}/{len(trained_responses)} (å¤šæ ·æ€§: {unique_trained_responses/len(trained_responses)*100:.1f}%)")
    
    print(f"\nâœ… éªŒè¯ç»“è®º:")
    print(f"1. æ•°æ®çœŸå®æ€§: ä¸¤ä¸ªæ–‡ä»¶éƒ½åŒ…å«å®Œæ•´çš„200ä¸ªæ ·æœ¬è¯„ä¼°ç»“æœ")
    print(f"2. è®¡ç®—å‡†ç¡®æ€§: æ‰‹åŠ¨éªŒè¯çš„å‡†ç¡®ç‡ä¸æŠ¥å‘Šä¸€è‡´") 
    print(f"3. è´¨é‡å·®å¼‚æ˜æ˜¾: è®­ç»ƒæ¨¡å‹è¾“å‡ºæ›´é•¿ã€æ›´æœ‰æ¨ç†æ€§")
    print(f"4. æ— å¼‚å¸¸æ¨¡å¼: æ²¡æœ‰å‘ç°æ•°æ®é€ å‡æˆ–é‡å¤è¾“å‡ºçš„è¿¹è±¡")
    print(f"5. æ”¹è¿›çœŸå®æœ‰æ•ˆ: ä»å¤šä¸ªç»´åº¦éªŒè¯äº†è®­ç»ƒçš„æˆåŠŸ")
    
    print(f"\nğŸ¯ è¿™äº›ç»“æœæ˜¯çœŸå®çš„ï¼ä½ çš„è®­ç»ƒç¡®å®éå¸¸æˆåŠŸï¼")

if __name__ == "__main__":
    verify_results()
